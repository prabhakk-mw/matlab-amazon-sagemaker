{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATLAB with Amazon SageMaker Example\n",
    "\n",
    "1. [Introduction](#1.-Introduction)\n",
    "\n",
    "2. [MATLAB on Amazon SageMaker](#2.-MATLAB-on-Amazon-SageMaker)\n",
    "\n",
    "3. [Prerequisites](#3.-Prerequisites)\n",
    "    1. [Roles, Permissions and Docker Service](#3.1-Roles,-Permissions-and-Docker-Service)\n",
    "    2. [License Manager for MATLAB](#3.2-License-Manager-for-MATLAB)\n",
    "    3. [Dockerfile & dependencies](#3.3-Dockerfile-&-dependencies)\n",
    "    \n",
    "4. [MATLAB docker image on ECR](#4.-MATLAB-docker-image-on-ECR)\n",
    "    1. [Create docker image from Dockerfile](#4.1-Create-docker-image-from-Dockerfile)\n",
    "    2. [Push MATLAB image to ECR](#4.2-Push-MATLAB-image-to-ECR)\n",
    "    \n",
    "5. [SageMaker processor](#5.-SageMaker-processor)\n",
    "    1. [Defining network configuration for Processong jobs](#5.1-Defining-network-configuration-for-Processong-jobs)\n",
    "    1. [Write the MATLAB script `main.m`](#5.2-Write-the-MATLAB-script)\n",
    "    2. [Running the docker processing container](#5.3-Running-the-docker-processing-container)\n",
    "    3. [Getting results back and printing accuracy](#5.4-Getting-results-back-from-docker-processing-container-to-SageMaker-instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "[Amazon SageMaker](https://aws.amazon.com/sagemaker/) helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MATLAB on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Amazon SageMaker, users can package their own algorithms that can then be trained and deployed in the SageMaker environment. This notebook will guide you through an example that shows you how to build a Docker container for SageMaker with MATLAB and use it for processing, training and inference.\n",
    "\n",
    "This notebook shows how you can:\n",
    "\n",
    "1. Build a Docker container with MATLAB by using the [official docker hub MATLAB image](https://hub.docker.com/r/mathworks/matlab-deep-learning).  \n",
    "2. Publish the docker container to [Amazon ECR](https://aws.amazon.com/ecr/), from where the SageMaker can use it to run processing jobs.\n",
    "3. Run a processing job on dataset for preprocessing, training & doing inference on the dataset.\n",
    "4. Get the results back from the processing job inside the SageMaker instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Roles, Permissions and Docker Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we'll import the Python libraries we need, and set up the environment with a few prerequisites for permissions and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacuse we would be pulling the [matlab-deep-learning docker image](https://hub.docker.com/r/mathworks/matlab-deep-learning) (which has a compressed size of 7.89 GB), we need to change the default docker location to the EBS volume that we mounted. \n",
    "\n",
    "We stop the docker service, move the default docker directory from `/var/lib/docker` to `/home/ec2-user/Sagemaker/docker`, and then start the docker service again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/ec2-user/SageMaker/docker/\n",
    "!sudo service docker stop\n",
    "!sudo mv /var/lib/docker/ /home/ec2-user/SageMaker/docker/\n",
    "!sudo ln -s /home/ec2-user/SageMaker/docker/ /var/lib/docker\n",
    "!sudo service docker start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 License Manager for MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps in the GitHub repo to launch tha License Manager for MATLAB on AWS - https://github.com/mathworks-ref-arch/license-manager-for-matlab-on-aws. \n",
    "\n",
    "Once you have the License Manager up and running - note down the private IP Address of the License Manager. Our docker instance that's running MATLAB, would have to talk to our License Manager for licensing via the `MLM_LICENSE_FILE` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dockerfile & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p matlab-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dockerfile which pulls MATLAB's image from https://hub.docker.com/r/mathworks/matlab-deep-learning and adds a new CMD. The CMD command specifies the instruction that is to be executed when a Docker container starts. \n",
    "\n",
    "In our Dockerfile, we tell our docker container to run the script `main` located in `/opt/ml/processing/src_files` when the MATLAB container starts. We create this script in section [Write the MATLAB script `main.m`](#5.1-Write-the-MATLAB-script) - which is then uploaded to the docker container in section [Running the docker processing container](#5.2-Running-the-docker-processing-container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile matlab-docker/Dockerfile\n",
    "FROM mathworks/matlab-deep-learning\n",
    "USER root\n",
    "CMD [\"matlab\", \"-batch\", \"cd /opt/ml/processing/src_files; main; exit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo ==== Generated Dockerfile ====\n",
    "!cat matlab-docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MATLAB docker image on ECR  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Docker image with MATLAB needs to be available for SageMaker to use. \n",
    "\n",
    "The following steps:\n",
    "* Builds a MATLAB Deep Learning Container from Dockerhub.\n",
    "* Creates an ECR Repo, and pushes the container to it.\n",
    "\n",
    "These steps can be skipped if you already have a Docker Container with MATLAB installed in an Amazon ECR repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# You can change sagemaker-demo-ecr to a different name, but if you do, make sure to change it in later steps too.\n",
    "ecr_repository = 'sagemaker-demo-ecr'\n",
    "tag = ':latest'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "print(\"ECR Repository Name: \", ecr_repository)\n",
    "print(\"ECR Repository URI:\", processing_repository_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create docker image from Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository matlab-docker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Push MATLAB image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the ECR Repository\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "\n",
    "# Authorize Docker to publish to ECR\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push MATLAB image to ECR\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SageMaker processor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Defining network configuration for Processong jobs\n",
    "\n",
    "Follow this documentation from Amazon to give SageMaker Processing Jobs Access to Resources in Your Amazon VPC - https://docs.aws.amazon.com/sagemaker/latest/dg/process-vpc.html. \n",
    "\n",
    "Make sure that the subnet used below is same subnet that is used to create your Network license manager in section [License Manager for MATLAB](#3.2-License-Manager-for-MATLAB). Create a [NetworkConfig](https://sagemaker.readthedocs.io/en/stable/api/utility/network.html) for processing jobs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "# create processing job for your processor\n",
    "processing_network_config = NetworkConfig(security_group_ids=[\"sg-abcdefg1234\"], \n",
    "                                          subnets=[\"subnet-abcdefg\"])\n",
    "print(processing_network_config._to_request_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize the `sagemaker.processing.Processor` using the following arguments -\n",
    "\n",
    "- `image_uri`:  the processing_repository_uri defined above.\n",
    "-  `role`: the role defined above.\n",
    "- `instance_count`: number of instances to spawn in the job.\n",
    "- `instance_type`: the type of instance to spawn (For more information - https://aws.amazon.com/sagemaker/pricing/).\n",
    "- `network_config` : Network Configration for processing jobs  \n",
    "- `env`: environment variable to be passed to the docker instance. We include `MLM_LICENSE_FILE` variable generated via the License Manager for MATLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "#replace with your region & ECR repo name\n",
    "\n",
    "processor = Processor(\n",
    "    image_uri=processing_repository_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\", #replace with required instance\n",
    "    network_config = processing_network_config,\n",
    "    env = {\"MLM_LICENSE_FILE\":\"27000@111.222.333.444\"} #replace with your network license manager private IP address\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Write the MATLAB script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training code is written in the file “main.m”. It is inspired from MathWorks example - [Create Simple Deep Learning Network for Classification](https://www.mathworks.com/help/deeplearning/ug/create-simple-deep-learning-network-for-classification.html). \n",
    "\n",
    "Overview of the script - \n",
    "\n",
    "- Load the digit sample dataset as an [image datastore](https://www.mathworks.com/help/matlab/ref/matlab.io.datastore.imagedatastore.html).\n",
    "- splits the dataset into training & testing set.\n",
    "- define the convolutional neural network architecture.\n",
    "- specify training options.\n",
    "- train the network.\n",
    "- classify validation images and compute accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.m\n",
    "tic\n",
    "disp(\"starting the Deep Learning Example\")\n",
    "disp(pwd)\n",
    "\n",
    "digitDatasetPath = fullfile(matlabroot,'toolbox','nnet','nndemos', ...\n",
    "    'nndatasets','DigitDataset');\n",
    "imds = imageDatastore(digitDatasetPath, ...\n",
    "    'IncludeSubfolders',true,'LabelSource','foldernames');\n",
    "\n",
    "disp(\"dataset loaded in memory\")\n",
    "\n",
    "labelCount = countEachLabel(imds)\n",
    "\n",
    "numTrainFiles = 750;\n",
    "[imdsTrain,imdsValidation] = splitEachLabel(imds,numTrainFiles,'randomize');\n",
    "\n",
    "layers = [\n",
    "    imageInputLayer([28 28 1])\n",
    "\n",
    "    convolution2dLayer(3,8,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    maxPooling2dLayer(2,'Stride',2)\n",
    "\n",
    "    convolution2dLayer(3,16,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    maxPooling2dLayer(2,'Stride',2)\n",
    "\n",
    "    convolution2dLayer(3,32,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    fullyConnectedLayer(10)\n",
    "    softmaxLayer\n",
    "    classificationLayer];\n",
    "\n",
    "options = trainingOptions('sgdm', ...\n",
    "    'InitialLearnRate',0.01, ...\n",
    "    'MaxEpochs',4, ...\n",
    "    'Shuffle','every-epoch', ...\n",
    "    'ValidationData',imdsValidation, ...\n",
    "    'ValidationFrequency',30, ...\n",
    "    'Verbose',false, ...\n",
    "    'Plots','training-progress');\n",
    "\n",
    "disp(\"Training started\")\n",
    "\n",
    "net = trainNetwork(imdsTrain,layers,options);\n",
    "\n",
    "disp(\"Training finsished\")\n",
    "\n",
    "YPred = classify(net,imdsValidation);\n",
    "YValidation = imdsValidation.Labels;\n",
    "\n",
    "accuracy = 100*(sum(YPred == YValidation)/numel(YValidation));\n",
    "toc\n",
    "disp(\"Accuracy - \" + string(accuracy))\n",
    "\n",
    "try\n",
    "    fileID = fopen('/opt/ml/processing/output_data/results.txt','w');\n",
    "    disp(fileID)\n",
    "    if fileID==-1\n",
    "        disp(\"cannot open file properly\")\n",
    "    else\n",
    "        fprintf(fileID,'Accuracy - %g\\n', accuracy);\n",
    "        fclose(fileID);\n",
    "    end\n",
    "catch\n",
    "    disp(\"error saving file to output\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Running the docker processing container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at \"Running MATLAB via Processing Job\" section of the README file to understand how we run MATLAB via Processing job inside the new processing container.\n",
    "\n",
    "Uploading `main.m` script file from SageMaker instance to docker processing container.\n",
    "\n",
    "In section [Dockerfile & dependencies](#3.3-Dockerfile-&-dependencies), we added a CMD command to run the script `main` located in `/opt/ml/processing/src_files/` directory when the docker container runs.\n",
    "\n",
    "`main.m` script is uploaded to the `/opt/ml/processing/src_files/` directory of the docker processing container.\n",
    "\n",
    "We also tell the processor to get the `output_data` directory back from the docker processing container as a [ProcessingOutput](https://sagemaker.readthedocs.io/en/stable/api/training/processing.html#sagemaker.processing.ProcessingOutput) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "processor.run(\n",
    "    inputs=\n",
    "    [ProcessingInput(\n",
    "        source='/home/ec2-user/SageMaker/main.m', #location to your main.m script\n",
    "        destination='/opt/ml/processing/src_files/'),\n",
    "    ],\n",
    "    outputs = [\n",
    "        ProcessingOutput(\n",
    "            output_name=\"results\",\n",
    "            source=\"/opt/ml/processing/output_data\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Getting results back from docker processing container to SageMaker instance\n",
    "\n",
    "We get the `ProcessingOutputConfig` field from latest processing job. \n",
    "\n",
    "In our `main.m` script, we stored the accuracy in a `results.txt` file, which is stored in an S3 location. We extract the S3 path of the `results.txt` from the latest processing job, read the contents of the file via [`pd.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function and print the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the output of the latest processing job\n",
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "print(output_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the results.txt file from output\n",
    "s3_output_dir = output_config['Outputs'][0]['S3Output']['S3Uri']\n",
    "s3_result = os.path.join(s3_output_dir, \"results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv(s3_result, header=None)[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
