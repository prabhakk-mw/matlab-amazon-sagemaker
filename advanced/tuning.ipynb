{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a13079d",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "[Amazon SageMaker](https://aws.amazon.com/sagemaker/) helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352b1d1",
   "metadata": {},
   "source": [
    "## 2. MATLAB on Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff0bcfd",
   "metadata": {},
   "source": [
    "With Amazon SageMaker, users can package their own algorithms that can then be trained and deployed in the SageMaker environment. This notebook will guide you through an example that shows you how to build a MATLAB Docker container for SageMaker and use it for launching a [Hyperparameter Tuning Job](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateHyperParameterTuningJob.html).\n",
    "\n",
    "This notebook shows how you can:\n",
    "\n",
    "1. Build a Docker container with MATLAB by using the [official docker hub MATLAB image](https://hub.docker.com/r/mathworks/matlab-deep-learning).  \n",
    "2. Publish the docker container to [Amazon ECR](https://aws.amazon.com/ecr/), from where the SageMaker can use it to run tuning jobs.\n",
    "3. Create an [Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase) and [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) to launch a tuning job. \n",
    "4. Get the best training job from the set of hyperparameters job. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30183f16",
   "metadata": {},
   "source": [
    "## 3. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd50ce",
   "metadata": {},
   "source": [
    "### 3.1 Roles, Permissions and Docker Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a969606c",
   "metadata": {},
   "source": [
    "To get started, we'll import the Python libraries we need, and set up the environment with a few prerequisites for permissions and configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b08eba",
   "metadata": {},
   "source": [
    "Beacuse we would be pulling the [matlab-deep-learning docker image](https://hub.docker.com/r/mathworks/matlab-deep-learning) (which has a compressed size of 7.89 GB), we need to change the default docker location to the EBS volume that we mounted. \n",
    "\n",
    "We stop the docker service, move the default docker directory from `/var/lib/docker` to `/home/ec2-user/Sagemaker/docker`, and then start the docker service again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f737be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/ec2-user/SageMaker/docker/\n",
    "!sudo service docker stop\n",
    "!sudo mv /var/lib/docker/ /home/ec2-user/SageMaker/docker/\n",
    "!sudo ln -s /home/ec2-user/SageMaker/docker/ /var/lib/docker\n",
    "!sudo service docker start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e6a67",
   "metadata": {},
   "source": [
    "### 3.2 License Manager for MATLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbf5d3",
   "metadata": {},
   "source": [
    "Follow the steps in the GitHub repo to launch tha License Manager for MATLAB on AWS - https://github.com/mathworks-ref-arch/license-manager-for-matlab-on-aws. \n",
    "\n",
    "Once you have the License Manager up and running - note down the private IP Address of the License Manager. Our docker instance that's running MATLAB, would have to talk to our License Manager for licensing via the `MLM_LICENSE_FILE` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f0acf",
   "metadata": {},
   "source": [
    "### 3.3 Dockerfile & dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2536eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p matlab-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d95aa8",
   "metadata": {},
   "source": [
    "Create a dockerfile which pulls MATLAB's image from https://hub.docker.com/r/mathworks/matlab-deep-learning and adds a new CMD. The CMD command specifies the instruction that is to be executed when a Docker container starts. \n",
    "\n",
    "\n",
    "The docker container runs the `train` script located in `/opt/ml/input/data/train` when the MATLAB container starts, and set the `MLM_LICENSE_FILE` to use the License Manager created above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile matlab-docker/Dockerfile\n",
    "FROM mathworks/matlab-deep-learning:r2021b\n",
    "USER root\n",
    "ENV MLM_LICENSE_FILE=\"27000@123.12.12.123\"\n",
    "ENTRYPOINT [\"matlab\", \"-batch\", \"cd /opt/ml/input/data/code; tuning; exit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491175dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo ==== Generated Dockerfile ====\n",
    "!cat matlab-docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5567f",
   "metadata": {},
   "source": [
    "## 4. MATLAB docker image on ECR  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1e202",
   "metadata": {},
   "source": [
    "A Docker image with MATLAB needs to be available for SageMaker to use. \n",
    "\n",
    "The following steps:\n",
    "* Builds a MATLAB Deep Learning Container from Dockerhub.\n",
    "* Creates an ECR Repo, and pushes the container to it.\n",
    "\n",
    "These steps can be skipped if you already have a Docker Container with MATLAB installed in an [Amazon ECR repository](https://console.aws.amazon.com/ecr/home?region=us-east-1#).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e337ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Your ECR repo name\n",
    "ecr_repository = 'sagemaker-demo-ecr'\n",
    "tag = ':tuning'\n",
    "processing_repository_uri = '{}.dkr.ecr.{}.amazonaws.com/{}'.format(account_id, region, ecr_repository + tag)\n",
    "\n",
    "print(\"ECR Repository Name: \", ecr_repository)\n",
    "print(\"ECR Repository URI:\", processing_repository_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c90ffcd",
   "metadata": {},
   "source": [
    "### 4.1 Create docker image from Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ECR repository and push docker image\n",
    "!docker build -t $ecr_repository$tag matlab-docker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69084bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag {ecr_repository + tag} $processing_repository_uri\n",
    "!docker image ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7867d",
   "metadata": {},
   "source": [
    "### 4.2 Push MATLAB image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449efc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates the ECR Repository if it doesn't exist\n",
    "!aws ecr describe-repositories --repository-names ${ecr_repository} || aws ecr create-repository --repository-name ${ecr_repository}\n",
    "\n",
    "# Authorize Docker to publish to ECR\n",
    "!aws ecr get-login-password --region {region} | docker login --username AWS --password-stdin {account_id}.dkr.ecr.{region}.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push MATLAB image to ECR\n",
    "!docker push $processing_repository_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eadde",
   "metadata": {},
   "source": [
    "## 5. MALTAB Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7892b",
   "metadata": {},
   "source": [
    "Overview of the script - \n",
    "\n",
    "- read hyperparameters from the `hyperparameters.json` file.\n",
    "- load the digit sample dataset as an [image datastore](https://www.mathworks.com/help/matlab/ref/matlab.io.datastore.imagedatastore.html).\n",
    "- split the dataset into training & testing set.\n",
    "- define the convolutional neural network architecture.\n",
    "- specify training options.\n",
    "- train the network.\n",
    "- save the trained model in the S3 models URI.\n",
    "- classify validation images and compute accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf679b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tuning.m\n",
    "\n",
    "rng(10); % For reproducibility\n",
    "\n",
    "tic\n",
    "\n",
    "disp('starting the Hyperparameter optimisation Example (KNN)')\n",
    "disp(pwd)\n",
    "\n",
    "prefixPath = '/opt/ml/'\n",
    "outputPath = append(prefixPath, 'output/')\n",
    "modelPath = append(prefixPath, 'model/')\n",
    "hyperparamPath = append(prefixPath, 'input/config/hyperparameters.json')\n",
    "\n",
    "if isfile('/opt/ml/input/config/hyperparameters.json')\n",
    "    type '/opt/ml/input/config/hyperparameters.json'\n",
    "else\n",
    "    disp('no hyperpatamers file')\n",
    "end\n",
    "\n",
    "% Reading hyperpatemrs for this training job -\n",
    "fid = fopen(hyperparamPath);\n",
    "raw = fread(fid,inf);\n",
    "str = char(raw');\n",
    "fclose(fid);\n",
    "val = jsondecode(str);\n",
    "\n",
    "if isfield(val, 'miniBatchSize')\n",
    "    miniBatchSize = val.miniBatchSize\n",
    "else\n",
    "    miniBatchSize = 64\n",
    "end\n",
    "if isfield(val, 'L2Regularization')\n",
    "    regularization = val.L2Regularization\n",
    "else\n",
    "    regularization = 1.0000e-04\n",
    "end\n",
    "\n",
    "\n",
    "digitDatasetPath = fullfile(matlabroot,'toolbox','nnet','nndemos', ...\n",
    "    'nndatasets','DigitDataset');\n",
    "imds = imageDatastore(digitDatasetPath, ...\n",
    "    'IncludeSubfolders',true,'LabelSource','foldernames');\n",
    "disp('dataset loaded in memory')\n",
    "\n",
    "[imdsTrain,imdsValidation] = splitEachLabel(imds,750,'randomize');\n",
    "\n",
    "layers = [\n",
    "    imageInputLayer([28 28 1])\n",
    "\n",
    "    convolution2dLayer(3,8,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    maxPooling2dLayer(2,'Stride',2)\n",
    "\n",
    "    convolution2dLayer(3,16,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    maxPooling2dLayer(2,'Stride',2)\n",
    "\n",
    "    convolution2dLayer(3,32,'Padding','same')\n",
    "    batchNormalizationLayer\n",
    "    reluLayer\n",
    "\n",
    "    fullyConnectedLayer(10)\n",
    "    softmaxLayer\n",
    "    classificationLayer];\n",
    "\n",
    "options = trainingOptions('sgdm', ...\n",
    "    'InitialLearnRate',0.01, ...\n",
    "    'MaxEpochs',4, ...\n",
    "    'Shuffle','every-epoch', ...\n",
    "    'ValidationData',imdsValidation, ...\n",
    "    'ValidationFrequency',30, ...\n",
    "    'Verbose',false, ...\n",
    "    'MiniBatchSize',miniBatchSize, ...\n",
    "    'L2Regularization',regularization, ...\n",
    "    'Plots','training-progress');\n",
    "\n",
    "disp('Training started')\n",
    "\n",
    "net = trainNetwork(imdsTrain,layers,options);\n",
    "save(append(modelPath, 'model.mat'),'net')\n",
    "disp('Training finsished')\n",
    "\n",
    "YPred = classify(net,imdsValidation);\n",
    "YValidation = imdsValidation.Labels;\n",
    "accuracy = 100*(sum(YPred == YValidation)/numel(YValidation));\n",
    "\n",
    "toc\n",
    "\n",
    "disp(\"accuracy: \" + string(accuracy))\n",
    "\n",
    "try\n",
    "    fileID = fopen(append(modelPath, 'results.txt'),'w');\n",
    "    disp(fileID)\n",
    "    if fileID==-1\n",
    "        disp('cannot open file properly')\n",
    "    else\n",
    "        fprintf(fileID,'accuracy - %g\\n', accuracy);\n",
    "        fclose(fileID);\n",
    "    end\n",
    "catch\n",
    "    disp('error saving file to output')\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd81170",
   "metadata": {},
   "source": [
    "Upload the `hyper.m` script to the S3 bucket for the MATLAB deep learning container to access it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change sagemaker-demo-bucket to a different S3 bucket as well\n",
    "bucket = 'sagemaker-demo-bucket'\n",
    "prefix = 'digit-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70411536",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('tuning.m', bucket, f'{prefix}/code/tuning.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5efaa7",
   "metadata": {},
   "source": [
    "Create [SageMaker Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase) with the following arguments - \n",
    "\n",
    "- Set `subnets` and `security_group_ids`, same as the network license manager in section [License Manager for MATLAB](#3.2-License-Manager-for-MATLAB).\n",
    "\n",
    "- Set `use_spot_instances` argument, to use [Spot Training in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) to optimize the cost of training models up to 90% over on-demand instances. \n",
    "- Set `max_wait` flag time in seconds for training (default: 24 * 60 * 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "- Set `max_run` flag time in seconds waiting for spot training job. After this amount of time Amazon SageMaker will stop waiting for managed spot training job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04939a9",
   "metadata": {},
   "source": [
    "## 6. SageMaker Estimator & HyperparameterTuner "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2173516",
   "metadata": {},
   "source": [
    "### 6.1 SageMaker Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=processing_repository_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    volume_size=30,\n",
    "    subnets=[\"subnet-abcd123\"], \n",
    "    security_group_ids=[\"sg-abcdefg123\"],\n",
    "    output_path=\"s3://{}/{}/output\".format(bucket, prefix),\n",
    "    use_spot_instances=True,\n",
    "    max_wait=60*50,\n",
    "    max_run=60*30,\n",
    "    hyperparameters={\"miniBatchSize\": 64, \"L2Regularization\":0.0001},\n",
    ")  # Setting constant hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ba4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the default hyperparameters defined above\n",
    "estimator.fit({\"code\": \"s3://{}/{}/code\".format(bucket, prefix)}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e253dc",
   "metadata": {},
   "source": [
    "### 6.2 Hyperparamter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for sagemaker tuning \n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter ranges for your tuning job\n",
    "hyperparameter_ranges = {\n",
    "    \"miniBatchSize\": IntegerParameter(48, 64),\n",
    "    \"L2Regularization\": ContinuousParameter(0.0001, 0.001),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb87ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom objective metric for your tuning job\n",
    "objective_metric_name = \"accuracy\"\n",
    "metric_definitions = [{\"Name\": \"accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e4ca11",
   "metadata": {},
   "source": [
    "Create [Hyperparameter Tuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html) which consumes the Estimator, hyperparameter_ranges, metrics, etc. created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca5d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Hyperparameter Tuner\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    objective_type=\"Maximize\",\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec4761",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({\"code\": \"s3://{}/{}/code\".format(bucket, prefix)}, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeatedly ping to get the status of the tuning job\n",
    "import time\n",
    "\n",
    "status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "while status != \"Completed\":\n",
    "    status = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "    completed = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "\n",
    "    prog = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "        HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    "    )[\"TrainingJobStatusCounters\"][\"InProgress\"]\n",
    "\n",
    "    print(f\"{status}, Completed Jobs: {completed}, In Progress Jobs: {prog}\")\n",
    "\n",
    "    time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a850430",
   "metadata": {},
   "source": [
    "### 6.3 Get the best training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bde38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the latest tuning job\n",
    "boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"BestTrainingJob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd623c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best training job from all the tuning jobs\n",
    "best_training = boto3.client(\"sagemaker\").describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name\n",
    ")[\"BestTrainingJob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get S3 location for the model file\n",
    "best_model_s3 = boto3.client(\"sagemaker\").describe_training_job(\n",
    "    TrainingJobName=best_training[\"TrainingJobName\"]\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model for further analysis\n",
    "!mkdir -p best-model/\n",
    "!aws s3 cp $best_model_s3 best_model.tar.gz\n",
    "!tar -xzvf best_model.tar.gz -C ./best-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls best-model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
